{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae02839",
   "metadata": {},
   "source": [
    "# Sample code for performing obstacle avoidance #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ee24e",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc056ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/bitcraze/crazyflie-lib-python/blob/master/examples/autonomousSequence.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CrazyFlie imports:\n",
    "\n",
    "import cflib.crtp\n",
    "from cflib.crazyflie import Crazyflie\n",
    "from cflib.crazyflie.log import LogConfig\n",
    "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
    "from cflib.crazyflie.syncLogger import SyncLogger\n",
    "from cflib.positioning.position_hl_commander import PositionHlCommander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce9da5",
   "metadata": {},
   "source": [
    "Set your group number and camera number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb41bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_number = 22\n",
    "min_y_pos = -0.5\n",
    "max_y_pos = 0.1\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363ab6b",
   "metadata": {},
   "source": [
    "## Tune the red filtering ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758561cb",
   "metadata": {},
   "source": [
    "You can use the following cell to test and visualize the red filtering. This cell *not* make the drone fly. It will connect to the CrazyFlie camera and perform red filtering on the live video feed. You should use this cell to tune the HSV intervals, and then copy/paste your tuned intervals into the __check_contours__ function below. When tuning the intervals, keep in mind that the lighting in the environment can matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107adf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(camera)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    middle = frame[:, 165:315] # only looks at middle 1/3ish of x axis; takes entire y-axis\n",
    "    \n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (145, 35, 75)\n",
    "    ub1 = (180, 255, 255)\n",
    "    lb2 = (0, 75, 75)\n",
    "    ub2 = (20, 255, 255)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    #hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv1 = cv2.cvtColor(middle, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(middle, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Compute\n",
    "    cv2.imshow('mask', mask)    \n",
    "\n",
    "    # Hit q to quit.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5faef",
   "metadata": {},
   "source": [
    "## Helper functions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dde9dd",
   "metadata": {},
   "source": [
    "The following cell contains some sample functions which will be useful.\n",
    "\n",
    "In particular, __check_contours__ and __findGreatesContour__ will perform red filtering on the live camera feed and identify the obstacles. The red filtering is controlled by setting HSV intervals in the __check_contours__ function. Note that the intervals will require tuning and may vary on different drones/cameras.\n",
    "\n",
    "The __adjust_position__ function can also be modified for performing obstacle avoidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45694074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Get the current crazyflie position:\n",
    "def position_estimate(scf):\n",
    "    log_config = LogConfig(name='Kalman Variance', period_in_ms=500)\n",
    "    log_config.add_variable('kalman.varPX', 'float')\n",
    "    log_config.add_variable('kalman.varPY', 'float')\n",
    "    log_config.add_variable('kalman.varPZ', 'float')\n",
    "\n",
    "    with SyncLogger(scf, log_config) as logger:\n",
    "        for log_entry in logger:\n",
    "            data = log_entry[1]\n",
    "            x = data['kalman.varPX']\n",
    "            y = data['kalman.varPY']\n",
    "            z = data['kalman.varPZ']\n",
    "            \n",
    "    print(x, y, z)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "# Set the built-in PID controller:\n",
    "def set_PID_controller(cf):\n",
    "    # Set the PID Controller:\n",
    "    print('Initializing PID Controller')\n",
    "    cf.param.set_value('stabilizer.controller', '1')\n",
    "    cf.param.set_value('kalman.resetEstimation', '1')\n",
    "    time.sleep(0.1)\n",
    "    cf.param.set_value('kalman.resetEstimation', '0')\n",
    "    time.sleep(2)\n",
    "    return\n",
    "\n",
    "\n",
    "# Ascend and hover at 1m:\n",
    "def ascend_and_hover(cf):\n",
    "    # Ascend:\n",
    "    for y in range(5):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, y / 10)\n",
    "        time.sleep(0.1)\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(20):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
    "        time.sleep(0.1)\n",
    "    return\n",
    "\n",
    "\n",
    "# Sort through contours in the image\n",
    "def findGreatesContour(contours):\n",
    "    largest_area = 0\n",
    "    largest_contour_index = -1\n",
    "    i = 0\n",
    "    total_contours = len(contours)\n",
    "\n",
    "    while i < total_contours:\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_contour_index = i\n",
    "        i += 1\n",
    "\n",
    "    #print(largest_area)\n",
    "\n",
    "    return largest_area, largest_contour_index\n",
    "\n",
    "\n",
    "# Find contours in the image\n",
    "def check_contours(frame):\n",
    "\n",
    "    print('Checking image:')\n",
    "\n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (145, 35, 75)\n",
    "    ub1 = (180, 255, 255)\n",
    "    lb2 = (0, 75, 75)\n",
    "    ub2 = (20, 255, 255)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Use the OpenCV findContours function.\n",
    "    # Note that there are three outputs, but we discard the first one.    \n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_area, largest_contour_index = findGreatesContour(contours)\n",
    "    contour_x = -1\n",
    "    \n",
    "    if largest_contour_index != -1:\n",
    "        contour_x = np.mean(contours[largest_contour_index], axis=0).flatten()[0]\n",
    "    \n",
    "        #print(largest_area)\n",
    "    \n",
    "        if largest_area > 100:\n",
    "            return mask, True, contour_x\n",
    "            \n",
    "    return mask, False, contour_x\n",
    "\n",
    "\n",
    "# Follow the setpoint sequence trajectory:\n",
    "def adjust_position(cf, current_x, current_y, direction):\n",
    "\n",
    "    print('Adjusting position')\n",
    "\n",
    "    steps_per_meter = int(10)\n",
    "    # Set the number here (the iterations of the for-loop) to the number of side steps.\n",
    "    # You may choose to tune the number and size of the steps.\n",
    "    for i in range(3): \n",
    "        if direction == \"RIGHT\":\n",
    "            current_y = current_y - 1.0/float(steps_per_meter)   \n",
    "        elif direction == \"FORWARD\":\n",
    "            current_x = current_x + 1.0/float(steps_per_meter)\n",
    "        elif direction == \"LEFT\":\n",
    "            current_y = current_y + 1.0/float(steps_per_meter)\n",
    "\n",
    "        position = [current_x, current_y, 0.5, 0.0]\n",
    "                        \n",
    "        print('Setting position {}'.format(position))\n",
    "        for i in range(10):\n",
    "            \"\"\"\n",
    "            cf.commander.send_position_setpoint(position[0],\n",
    "                                                position[1],\n",
    "                                                position[2],\n",
    "                                                position[3])\n",
    "            \"\"\"\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    #cf.commander.send_stop_setpoint()\n",
    "    # Make sure that the last packet leaves before the link is closed.\n",
    "    # The message queue is not flushed before closing.\n",
    "    #time.sleep(0.05)\n",
    "    return current_x, current_y\n",
    "\n",
    "\n",
    "# Hover, descend, and stop all motion:\n",
    "def hover_and_descend(cf):\n",
    "    print('Descending:')\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(30):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
    "        time.sleep(0.1)\n",
    "    # Descend:\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, (10 - y) / 25)\n",
    "        time.sleep(0.1)\n",
    "    # Stop all motion:\n",
    "    for i in range(10):\n",
    "        cf.commander.send_stop_setpoint()\n",
    "        time.sleep(0.1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fbec4",
   "metadata": {},
   "source": [
    "## Test obstacle avoidance on the CrazyFlie ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd18e2",
   "metadata": {},
   "source": [
    "The following cell *will* fly the drone. Place the CrazyFlie in front of an obstacle in the netted area for testing. This cell will perform object detection and avoidance using the red filtering defined in the helper functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca756a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" NOT MOST UP TO DATE \"\"\"\n",
    "\n",
    "\n",
    "# Set the URI the Crazyflie will connect to\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "# Check that CrazyFlie devices are available:\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascent to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "        current_x = 0.0\n",
    "        current_y = 0.0\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "        direction = \"RIGHT\"\n",
    "\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        #while(cap.isOpened()):\n",
    "        #while(current_y < 30):\n",
    "        while(cap.isOpened() and elapsed < 45):\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            elapsed = time.time() - t\n",
    "            \n",
    "            if(elapsed > 5.0):\n",
    "                print(\"chk3\")\n",
    "                print('Capturing.....')\n",
    "\n",
    "                if ret:\n",
    "                    print(\"chk4\")\n",
    "                    frame = frame[:, 165:315] # only looks at middle 1/3ish of x axis; takes entire y-axis\n",
    "                    print(\"chk5\")\n",
    "                    cv2.imshow('frame',frame)\n",
    "                    print(\"chk6\")\n",
    "                    \n",
    "                    if(ascended_bool==0):\n",
    "                        set_PID_controller(cf)\n",
    "                        ascend_and_hover(cf)\n",
    "                        ascended_bool = 1\n",
    "                    else:\n",
    "\n",
    "                        if(check_contours(frame)):\n",
    "                            print(\"theres a contour\")\n",
    "                            if current_y < min_y_pos:\n",
    "                                direction = \"LEFT\"\n",
    "                            elif current_y > max_y_pos:\n",
    "                                direction = \"RIGHT\"   \n",
    "                            \n",
    "                        else:\n",
    "                            direction = \"FORWARD\"\n",
    "\n",
    "                        print(\"going %s\" %(direction))\n",
    "                        current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "\n",
    "                    \n",
    "            \n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Descend and stop all motion:\n",
    "        hover_and_descend(cf)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9734502d-91d0-444c-9254-2b4f2378662e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning interfaces for Crazyflies...\n",
      "Crazyflies found:\n",
      "radio://0/76/250K\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/9/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/8/2M\n",
      "radio://0/10/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/8/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/9/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/9/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/10/2M\n",
      "radio://0/13/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n",
      "radio://0/5/2M\n",
      "radio://0/8/2M\n",
      "radio://0/13/2M\n",
      "radio://0/14/2M\n",
      "radio://0/22/2M\n",
      "radio://0/23/2M\n",
      "radio://0/24/2M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1748.918] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking image:\n",
      "[[347.92791411 352.00613497]]\n",
      "theres a contour\n",
      "going RIGHT\n",
      "Adjusting position\n",
      "Setting position [0, -0.1, 0.5, 0.0]\n",
      "Setting position [0, -0.2, 0.5, 0.0]\n",
      "Setting position [0, -0.30000000000000004, 0.5, 0.0]\n",
      "Checking image:\n",
      "[[352.18627451 348.01143791]]\n",
      "theres a contour\n",
      "going RIGHT\n",
      "Adjusting position\n",
      "Setting position [0, -0.4, 0.5, 0.0]\n",
      "Setting position [0, -0.5, 0.5, 0.0]\n",
      "Setting position [0, -0.6, 0.5, 0.0]\n",
      "Checking image:\n",
      "[[354.95169082 347.85185185]]\n",
      "theres a contour\n",
      "going LEFT\n",
      "Adjusting position\n",
      "Setting position [0, -0.5, 0.5, 0.0]\n",
      "Setting position [0, -0.4, 0.5, 0.0]\n",
      "Setting position [0, -0.30000000000000004, 0.5, 0.0]\n",
      "Checking image:\n",
      "[[361.47466216 347.94763514]]\n",
      "theres a contour\n",
      "going RIGHT\n",
      "Adjusting position\n",
      "Setting position [0, -0.4, 0.5, 0.0]\n",
      "Setting position [0, -0.5, 0.5, 0.0]\n",
      "Setting position [0, -0.6, 0.5, 0.0]\n",
      "Checking image:\n",
      "[[360.79067122 357.11604096]]\n",
      "theres a contour\n",
      "going LEFT\n",
      "Adjusting position\n",
      "Setting position [0, -0.5, 0.5, 0.0]\n",
      "Setting position [0, -0.4, 0.5, 0.0]\n",
      "Setting position [0, -0.30000000000000004, 0.5, 0.0]\n",
      "Checking image:\n",
      "[[364.77266754 351.16425756]]\n",
      "theres a contour\n",
      "going RIGHT\n",
      "Adjusting position\n",
      "Setting position [0, -0.4, 0.5, 0.0]\n",
      "Setting position [0, -0.5, 0.5, 0.0]\n",
      "Setting position [0, -0.6, 0.5, 0.0]\n",
      "Checking image:\n",
      "[[361.7393617  338.01728723]]\n",
      "theres a contour\n",
      "going LEFT\n",
      "Adjusting position\n",
      "Setting position [0, -0.5, 0.5, 0.0]\n",
      "Setting position [0, -0.4, 0.5, 0.0]\n",
      "Setting position [0, -0.30000000000000004, 0.5, 0.0]\n",
      "Checking image:\n",
      "[[349.1163575  360.65261383]]\n",
      "theres a contour\n",
      "going RIGHT\n",
      "Adjusting position\n",
      "Setting position [0, -0.4, 0.5, 0.0]\n",
      "Setting position [0, -0.5, 0.5, 0.0]\n",
      "Setting position [0, -0.6, 0.5, 0.0]\n",
      "Checking image:\n",
      "[[488.96778043 442.34128878]]\n",
      "theres a contour\n",
      "going LEFT\n",
      "Adjusting position\n",
      "Setting position [0, -0.5, 0.5, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got link error callback [Too many packets lost] in state [2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting position [0, -0.4, 0.5, 0.0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 151\u001B[0m\n\u001B[1;32m    148\u001B[0m     direction \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFORWARD\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgoing \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m(direction))\n\u001B[0;32m--> 151\u001B[0m current_x, current_y \u001B[38;5;241m=\u001B[39m \u001B[43madjust_position\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;66;03m# Check image\u001B[39;00m\n\u001B[1;32m    154\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m, mask)\n",
      "Cell \u001B[0;32mIn[22], line 129\u001B[0m, in \u001B[0;36madjust_position\u001B[0;34m(cf, current_x, current_y, direction)\u001B[0m\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m    123\u001B[0m \u001B[38;5;250m        \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;124;03m        cf.commander.send_position_setpoint(position[0],\u001B[39;00m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;124;03m                                            position[1],\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;124;03m                                            position[2],\u001B[39;00m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m                                            position[3])\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m        \"\"\"\u001B[39;00m\n\u001B[0;32m--> 129\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;66;03m#cf.commander.send_stop_setpoint()\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;66;03m# Make sure that the last packet leaves before the link is closed.\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;66;03m# The message queue is not flushed before closing.\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;66;03m#time.sleep(0.05)\u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m current_x, current_y\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" going off of lab 8 UP TO DATE VERSION \"\"\"\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "# load the COCO class names\n",
    "with open('Lab8_Supplement/object_detection_classes_coco.txt', 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "\n",
    "# get a different color array for each of the classes\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "# load the DNN model\n",
    "#model = cv2.dnn.readNet(model='Lab8_Supplement/frozen_inference_graph.pb',\n",
    "#                        config='Lab8_Supplement/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt', \n",
    "#  framework='TensorFlow')                     \n",
    "\"\"\"\n",
    "# ************ Parameters that might be useful to change ************ \n",
    "# COCO label id that we want to track\n",
    "tracking_label = 1 # PERSON (1), CHAIR (62)\n",
    "\n",
    "# Set the URI the Crazyflie will connect to\n",
    "group_number = 22\n",
    "uri = f'radio://0/22/2M'\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 0\n",
    "\n",
    "# Confidence of detection\n",
    "confidence = 0.7\n",
    "\n",
    "# ******************************************************************\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascend to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        ascended_bool = 0\n",
    "        direction = \"RIGHT\"\n",
    "\n",
    "        # capture the video\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        \n",
    "        # get the video frames' width and height\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "\n",
    "        # flag indicating whether to exit the main loop and then descend\n",
    "        exit_loop = False\n",
    "\n",
    "        # Ascend and hover a bit\n",
    "        #set_PID_controller(cf)\n",
    "        #ascend_and_hover(cf)\n",
    "        #time.sleep(1)\n",
    "        \n",
    "        current_x = 0\n",
    "        current_y = 0\n",
    "        \n",
    "        # detect objects in each frame of the video\n",
    "        while cap.isOpened() and not exit_loop:\n",
    "            \n",
    "            # Try to read image\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "\n",
    "                mask, contour_bool, contour_x = check_contours(frame)\n",
    "                # if drone is near boundaries, move towards center\n",
    "                if current_y < min_y_pos:\n",
    "                    direction = \"LEFT\"\n",
    "                    current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "                    current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "                    \n",
    "                elif current_y > max_y_pos:\n",
    "                    direction = \"RIGHT\"\n",
    "                    current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "                    current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "\n",
    "                else:  \n",
    "                    if(contour_bool):\n",
    "                        print(\"theres a contour\")\n",
    "                        # if obstacle is not centered in image, move forward\n",
    "                        if contour_x < 210 or contour_x > 450:\n",
    "                            direction = \"FORWARD\"\n",
    "                        elif contour_x < 330:\n",
    "                            direction = \"RIGHT\"\n",
    "                        else:\n",
    "\n",
    "                    # if no obstacle is visible, move forward\n",
    "                    else:\n",
    "                        direction = \"FORWARD\"\n",
    "\n",
    "                    print(\"going %s\" %(direction))\n",
    "                    current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "\n",
    "                # Check image\n",
    "                cv2.imshow('mask', mask)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                print('no image!!')\n",
    "                \n",
    "        cap.release()\n",
    "        \n",
    "        # Descend and stop all motion:\n",
    "        print('target reached!')\n",
    "        #hover_and_descend(cf)\n",
    "        \n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9b314-7842-4072-b459-14b06fd1daf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
