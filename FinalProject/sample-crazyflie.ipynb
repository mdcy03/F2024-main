{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae02839",
   "metadata": {},
   "source": [
    "# Sample code for performing obstacle avoidance #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ee24e",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "id": "bfc056ed",
   "metadata": {},
   "source": [
    "# Code adapted from: https://github.com/bitcraze/crazyflie-lib-python/blob/master/examples/autonomousSequence.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CrazyFlie imports:\n",
    "\n",
    "import cflib.crtp\n",
    "from cflib.crazyflie import Crazyflie\n",
    "from cflib.crazyflie.log import LogConfig\n",
    "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
    "from cflib.crazyflie.syncLogger import SyncLogger\n",
    "from cflib.positioning.position_hl_commander import PositionHlCommander"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6fce9da5",
   "metadata": {},
   "source": [
    "Set your group number and camera number."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "group_number = 21\n",
    "min_y_pos = -1\n",
    "max_y_pos = 1\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 0"
   ],
   "id": "bbed3339e6d2d248",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0363ab6b",
   "metadata": {},
   "source": [
    "## Tune the red filtering ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758561cb",
   "metadata": {},
   "source": [
    "You can use the following cell to test and visualize the red filtering. This cell *not* make the drone fly. It will connect to the CrazyFlie camera and perform red filtering on the live video feed. You should use this cell to tune the HSV intervals, and then copy/paste your tuned intervals into the __check_contours__ function below. When tuning the intervals, keep in mind that the lighting in the environment can matter."
   ]
  },
  {
   "cell_type": "code",
   "id": "107adf87",
   "metadata": {},
   "source": [
    "cap = cv2.VideoCapture(camera)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    middle = frame[:, 165:315] # only looks at middle 1/3ish of x axis; takes entire y-axis\n",
    "    \n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (145, 35, 75)\n",
    "    ub1 = (180, 255, 255)\n",
    "    lb2 = (0, 75, 75)\n",
    "    ub2 = (20, 255, 255)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    #hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv1 = cv2.cvtColor(middle, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(middle, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Compute\n",
    "    cv2.imshow('mask', mask)    \n",
    "\n",
    "    # Hit q to quit.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aee5faef",
   "metadata": {},
   "source": [
    "## Helper functions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dde9dd",
   "metadata": {},
   "source": [
    "The following cell contains some sample functions which will be useful.\n",
    "\n",
    "In particular, __check_contours__ and __findGreatesContour__ will perform red filtering on the live camera feed and identify the obstacles. The red filtering is controlled by setting HSV intervals in the __check_contours__ function. Note that the intervals will require tuning and may vary on different drones/cameras.\n",
    "\n",
    "The __adjust_position__ function can also be modified for performing obstacle avoidance."
   ]
  },
  {
   "cell_type": "code",
   "id": "45694074",
   "metadata": {},
   "source": [
    "import sys\n",
    "\n",
    "# Get the current crazyflie position:\n",
    "def position_estimate(scf):\n",
    "    log_config = LogConfig(name='Kalman Variance', period_in_ms=500)\n",
    "    log_config.add_variable('kalman.varPX', 'float')\n",
    "    log_config.add_variable('kalman.varPY', 'float')\n",
    "    log_config.add_variable('kalman.varPZ', 'float')\n",
    "\n",
    "    with SyncLogger(scf, log_config) as logger:\n",
    "        for log_entry in logger:\n",
    "            data = log_entry[1]\n",
    "            x = data['kalman.varPX']\n",
    "            y = data['kalman.varPY']\n",
    "            z = data['kalman.varPZ']\n",
    "            \n",
    "    print(x, y, z)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "# Set the built-in PID controller:\n",
    "def set_PID_controller(cf):\n",
    "    # Set the PID Controller:\n",
    "    print('Initializing PID Controller')\n",
    "    cf.param.set_value('stabilizer.controller', '1')\n",
    "    cf.param.set_value('kalman.resetEstimation', '1')\n",
    "    time.sleep(0.1)\n",
    "    cf.param.set_value('kalman.resetEstimation', '0')\n",
    "    time.sleep(2)\n",
    "    return\n",
    "\n",
    "\n",
    "# Ascend and hover at 1m:\n",
    "def ascend_and_hover(cf):\n",
    "    # Ascend:\n",
    "    for y in range(5):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, y / 10)\n",
    "        time.sleep(0.1)\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(20):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
    "        time.sleep(0.1)\n",
    "    return\n",
    "\n",
    "\n",
    "# Sort through contours in the image\n",
    "def findGreatesContour(contours):\n",
    "    largest_area = 0\n",
    "    largest_contour_index = -1\n",
    "    i = 0\n",
    "    total_contours = len(contours)\n",
    "\n",
    "    while i < total_contours:\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_contour_index = i\n",
    "        i += 1\n",
    "\n",
    "    #print(largest_area)\n",
    "\n",
    "    return largest_area, largest_contour_index\n",
    "\n",
    "\n",
    "# Find contours in the image\n",
    "def check_contours(frame):\n",
    "\n",
    "    print('Checking image:')\n",
    "\n",
    "    # These define the upper and lower HSV for the red obstacles.\n",
    "    # Note that the red color wraps around 180, so there are two intervals.\n",
    "    # Tuning of these values will vary depending on the camera.\n",
    "    lb1 = (145, 35, 75)\n",
    "    ub1 = (180, 255, 255)\n",
    "    lb2 = (0, 75, 75)\n",
    "    ub2 = (20, 255, 255)\n",
    "\n",
    "    # Perform contour detection on the input frame.\n",
    "    hsv1 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute mask of red obstacles in either color range.\n",
    "    mask1 = cv2.inRange(hsv1, lb1, ub1)\n",
    "    mask2 = cv2.inRange(hsv2, lb2, ub2)\n",
    "    # Combine the masks.\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Use the OpenCV findContours function.\n",
    "    # Note that there are three outputs, but we discard the first one.    \n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_area, largest_contour_index = findGreatesContour(contours)\n",
    "    contour_x = -1\n",
    "    \n",
    "    if largest_contour_index != -1:\n",
    "        contour_x = np.mean(contours[largest_contour_index], axis=0).flatten()[0]\n",
    "    \n",
    "        #print(largest_area)\n",
    "    \n",
    "        if largest_area > 100:\n",
    "            return mask, True, contour_x\n",
    "            \n",
    "    return mask, False, contour_x\n",
    "\n",
    "\n",
    "# Follow the setpoint sequence trajectory:\n",
    "def adjust_position(cf, current_x, current_y, direction):\n",
    "\n",
    "    print('Adjusting position')\n",
    "\n",
    "    steps_per_meter = int(10)\n",
    "    # Set the number here (the iterations of the for-loop) to the number of side steps.\n",
    "    # You may choose to tune the number and size of the steps.\n",
    "    for i in range(1): \n",
    "        if direction == \"RIGHT\":\n",
    "            current_y = current_y - 1.0/float(steps_per_meter)   \n",
    "        elif direction == \"FORWARD\":\n",
    "            current_x = current_x + 1.0/float(steps_per_meter)\n",
    "        elif direction == \"LEFT\":\n",
    "            current_y = current_y + 1.0/float(steps_per_meter)\n",
    "\n",
    "        position = [current_x, current_y, 0.5, 0.0]\n",
    "                        \n",
    "        print('Setting position {}'.format(position))\n",
    "        for i in range(10):\n",
    "            \n",
    "            cf.commander.send_position_setpoint(position[0],\n",
    "                                                position[1],\n",
    "                                                position[2],\n",
    "                                                position[3])\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "\n",
    "    #cf.commander.send_stop_setpoint()\n",
    "    # Make sure that the last packet leaves before the link is closed.\n",
    "    # The message queue is not flushed before closing.\n",
    "    #time.sleep(0.05)\n",
    "    return current_x, current_y\n",
    "\n",
    "\n",
    "# Hover, descend, and stop all motion:\n",
    "def hover_and_descend(cf):\n",
    "    print('Descending:')\n",
    "    # Hover at 0.5 meters:\n",
    "    for _ in range(30):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
    "        time.sleep(0.1)\n",
    "    # Descend:\n",
    "    for y in range(10):\n",
    "        cf.commander.send_hover_setpoint(0, 0, 0, (10 - y) / 25)\n",
    "        time.sleep(0.1)\n",
    "    # Stop all motion:\n",
    "    for i in range(10):\n",
    "        cf.commander.send_stop_setpoint()\n",
    "        time.sleep(0.1)\n",
    "    return"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f41fbec4",
   "metadata": {},
   "source": [
    "## Test obstacle avoidance on the CrazyFlie ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd18e2",
   "metadata": {},
   "source": [
    "The following cell *will* fly the drone. Place the CrazyFlie in front of an obstacle in the netted area for testing. This cell will perform object detection and avoidance using the red filtering defined in the helper functions above."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\" going off of lab 8 - UP TO DATE VERSION \"\"\"\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# # load the COCO class names\n",
    "# with open('Lab8_Supplement/object_detection_classes_coco.txt', 'r') as f:\n",
    "#     class_names = f.read().split('\\n')\n",
    "#\n",
    "# # get a different color array for each of the classes\n",
    "# COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "#\n",
    "# # load the DNN model\n",
    "# #model = cv2.dnn.readNet(model='Lab8_Supplement/frozen_inference_graph.pb',\n",
    "# #                        config='Lab8_Supplement/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt',\n",
    "# #  framework='TensorFlow')\n",
    "\n",
    "# ************ Parameters that might be useful to change ************ \n",
    "# COCO label id that we want to track\n",
    "tracking_label = 1 # PERSON (1), CHAIR (62)\n",
    "\n",
    "# Set the URI the Crazyflie will connect to\n",
    "group_number = 21\n",
    "uri = f'radio://0/{group_number}/2M'\n",
    "\n",
    "# Possibly try 0, 1, 2 ...\n",
    "camera = 0\n",
    "\n",
    "# Confidence of detection\n",
    "confidence = 0.7\n",
    "\n",
    "# ******************************************************************\n",
    "\n",
    "# Initialize all the CrazyFlie drivers:\n",
    "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
    "\n",
    "# Scan for Crazyflies in range of the antenna:\n",
    "print('Scanning interfaces for Crazyflies...')\n",
    "available = cflib.crtp.scan_interfaces()\n",
    "\n",
    "# List local CrazyFlie devices:\n",
    "print('Crazyflies found:')\n",
    "for i in available:\n",
    "    print(i[0])\n",
    "\n",
    "if len(available) == 0:\n",
    "    print('No Crazyflies found, cannot run example')\n",
    "else:\n",
    "    ## Ascend to hover; run the sequence; then descend from hover:\n",
    "    # Use the CrazyFlie corresponding to team number:\n",
    "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
    "        # Get the Crazyflie class instance:\n",
    "        cf = scf.cf\n",
    "\n",
    "        # Initialize and ascend:\n",
    "        t = time.time()\n",
    "        elapsed = time.time() - t\n",
    "        #ascended_bool = 0\n",
    "        direction = \"RIGHT\"\n",
    "\n",
    "        # capture the video\n",
    "        cap = cv2.VideoCapture(camera)\n",
    "        \n",
    "        # get the video frames' width and height\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "\n",
    "        # flag indicating whether to exit the main loop and then descend\n",
    "        exit_loop = False\n",
    "\n",
    "        # Ascend and hover a bit\n",
    "        set_PID_controller(cf)\n",
    "        ascend_and_hover(cf)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        current_x = 0\n",
    "        current_y = 0\n",
    "        \n",
    "        # detect objects in each frame of the video\n",
    "        while cap.isOpened() and not exit_loop:\n",
    "            \n",
    "            # Try to read image\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "\n",
    "                mask, contour_bool, contour_x = check_contours(frame)\n",
    "                # if drone is near boundaries, move towards center\n",
    "                if current_y < min_y_pos:\n",
    "                    direction = \"LEFT\"\n",
    "                    print(\"TOO FAR RIGHT\")\n",
    "                    current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "                    \n",
    "                elif current_y > max_y_pos:\n",
    "                    direction = \"RIGHT\"\n",
    "                    print(\"TOO FAR LEFT\")\n",
    "                    current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "\n",
    "                else:  \n",
    "                    if(contour_bool):\n",
    "                        print(\"theres a contour\")\n",
    "                        # if obstacle is not centered in image, move forward\n",
    "                        if contour_x < 210 or contour_x > 450:\n",
    "                            direction = \"FORWARD\"\n",
    "                        elif contour_x < 330:\n",
    "                            direction = \"RIGHT\"\n",
    "                        else:\n",
    "                            direction = \"LEFT\"\n",
    "\n",
    "                    # if no obstacle is visible, move forward\n",
    "                    # should implement search for book here (after passing obstacle field)\n",
    "                    else:\n",
    "                        direction = \"FORWARD\"\n",
    "\n",
    "                    print(\"going %s\" %(direction))\n",
    "                    current_x, current_y = adjust_position(cf, current_x, current_y, direction)\n",
    "\n",
    "                # Check image\n",
    "                cv2.imshow('mask', mask)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                print('no image!!')\n",
    "                \n",
    "        cap.release()\n",
    "        \n",
    "        # Descend and stop all motion:\n",
    "        print('target reached!')\n",
    "        hover_and_descend(cf)\n",
    "        \n",
    "        cv2.destroyAllWindows()"
   ],
   "id": "fcef2964a9bb1c90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d0f389cdc35d0efe",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
